{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Workflow stages\nThe competition solution workflow goes through seven stages described in the Data Science Solutions book.\n\n1. Question or problem definition.\n1. Acquire training and testing data.\n1. Wrangle, prepare, cleanse the data.\n1. Analyze, identify patterns, and explore the data.\n1. Model, predict and solve the problem.\n1. Visualize, report, and present the problem solving steps and final solution.\n1. Supply or submit the results."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random as rnd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ncombine = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()\nprint('_'*40)\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assumtions based on data analysis\n\n### Correlating.\n\nWe want to know how well does each feature correlate with Survival. We want to do this early in our project and match these quick correlations with modelled correlations later in the project.\n\n### Completing.\n\n1. We may want to complete Age feature as it is definitely correlated to survival.\n1. We may want to complete the Embarked feature as it may also correlate with survival or another important feature.\n\n### Correcting.\n\n1. Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation between Ticket and survival.\n1. Cabin feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\n1. PassengerId may be dropped from training dataset as it does not contribute to survival.\n1. Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped.\n\n### Creating.\n\n1. We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n1. We may want to engineer the Name feature to extract Title as a new feature.\n1. We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n1. We may also want to create a Fare range feature if it helps our analysis.\n\n### Classifying.\n\nWe may also add to our assumptions based on the problem description noted earlier.\n\n1. Women (Sex=female) were more likely to have survived.\n1. Children (Age<?) were more likely to have survived.\n1. The upper-class passengers (Pclass=1) were more likely to have survived."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size = 2.2, aspect = 1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before Dropping: \", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine=[train_df, test_df]\nprint(\"After Dropping: \", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rate\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Title'] = dataset['Title'].astype(int)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"guess_ages = np.zeros((2,3))\nguess_ages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            age_guess = guess_df.median()\n            guess_ages[i, j] = int(age_guess/0.5 + 0.5) * 0.5\n    print(guess_ages)\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[(dataset['Age'].isnull()) & (dataset['Sex'] == i) & (dataset['Pclass'] == j+1), 'Age'] = guess_ages[i, j]\n    dataset['Age'] = dataset['Age'].astype(int)\n\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['AgeBandChk'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBandChk', 'Survived']].groupby(['AgeBandChk'], as_index=False).mean().sort_values(by='AgeBandChk', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['AgeBand'] = dataset.Age * 0\n    dataset.loc[dataset['Age'] <= 16, 'AgeBand'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'AgeBand'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'AgeBand'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'AgeBand'] = 3\n    dataset.loc[dataset['Age'] > 64, 'AgeBand'] = 4\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['AgeBandChk'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['AgeBand*Class'] = dataset.AgeBand * dataset.Pclass\n\ntrain_df.loc[:, ['AgeBand*Class', 'AgeBand', 'Pclass']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_port = train_df.Embarked.dropna().mode()[0]\nprint(freq_port)\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'] .fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['FareBandChk'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBandChk', 'Survived']].groupby(['FareBandChk'], as_index=False).mean().sort_values(by='FareBandChk', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['FareBand'] = 0\n    dataset.loc[dataset['Fare'] <= 7.91, 'FareBand'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'FareBand'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31.0), 'FareBand'] = 2\n    dataset.loc[dataset['Fare'] > 31.0, 'FareBand'] = 3\n\ntrain_df = train_df.drop(['FareBandChk'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop('Survived', axis=1)\ny_train = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis=1).copy()\nX_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Coefficiency\n\ncoeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\ncoeff_df.sort_values(by='Correlation', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_logreg.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, y_train)*100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_svc.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# k-Nearest Neightbors (k-NN)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, y_train) * 100, 2)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_knn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nacc_gaussian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_gaussian.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, y_train)\ny_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, y_train)*100, 2)\nacc_perceptron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_perceptron.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\ny_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, y_train)*100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_linear-svc.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stochatic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\ny_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, y_train)*100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_sgd.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\ny_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train)*100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_decision_tree.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, y_train)*100, 2)\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('second_submission_random_forest.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Training Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree],\n    'Test Score': [0.67464, 0.65071, 0.76076, \n              0.74162, 0.76076, 0.69377, \n              0.71770, 0.67942, 0.68421]})\nmodels.sort_values(by='Test Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize', 'Fare', 'Age'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize', 'Fare', 'Age'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop('Survived', axis=1)\ny_train = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis=1).copy()\nX_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nprint(\"acc_log: \", acc_log)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_logreg.csv', index=False)\n\n# Support Vector Machine\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, y_train)*100, 2)\nprint(\"acc_svc: \", acc_svc)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_svc.csv', index=False)\n\n# k-Nearest Neightbors (k-NN)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, y_train) * 100, 2)\nprint(\"acc_knn: \", acc_knn)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_knn.csv', index=False)\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nprint(\"acc_gaussian: \", acc_gaussian)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_gaussian.csv', index=False)\n\n# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, y_train)\ny_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, y_train)*100, 2)\nprint(\"acc_perceptron: \", acc_perceptron)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_perceptron.csv', index=False)\n\n# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\ny_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, y_train)*100, 2)\nprint(\"acc_linear_svc: \", acc_linear_svc)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_linear-svc.csv', index=False)\n\n# Stochatic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\ny_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, y_train)*100, 2)\nprint(\"acc_sgd: \", acc_sgd)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_sgd.csv', index=False)\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\ny_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train)*100, 2)\nprint(\"acc_decision_tree: \", acc_decision_tree)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_decision_tree.csv', index=False)\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, y_train)*100, 2)\nprint(\"acc_random_forest: \", acc_random_forest)\nsubmission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\": y_pred})\nsubmission.to_csv('third_submission_random_forest.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models2 = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Training Score 2': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree],\n    'Test Score 2': [0.79425, 0.75119, 0.7799,\n                    0.77511, 0.75119, 0.7799,\n                    0.76555, 0.77511, 0.78468]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_merge = pd.merge(models, models2, on='Model')\nmodels_merge.sort_values(by='Training Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}